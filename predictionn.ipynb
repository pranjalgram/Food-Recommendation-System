{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_util(to_check_string,df_label_features,dataset_label):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix_breakfast = tfidf_vectorizer.fit_transform(df[dataset_label])\n",
    "    checker = tfidf_vectorizer.fit_transform([to_check_string,df_label_features])\n",
    "    pred_break = []\n",
    "    pred_break = cosine_similarity(checker[0], tfidf_matrix_breakfast)\n",
    "    pred_dict={}\n",
    "    count = 0;\n",
    "    for i in pred_break[0]:\n",
    "        pred_dict[i] = count\n",
    "        count = count + 1\n",
    "    #var_pred_list=[]    \n",
    "    var_pred_list = predicted_index_list(pred_dict)\n",
    "    final_to_pred = pred_(to_check_string,dataset_label,var_pred_list)\n",
    "    return final_to_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_index_list(pred_dict):\n",
    "    #getting first non zero index values from dictionary for varient prediction\n",
    "    var_pred_list = []\n",
    "    count_pred = 6 #for atmost 6 and atleast 5 values for prediction\n",
    "    temp_pred_dict = pred_dict\n",
    "    for save in sorted(temp_pred_dict,reverse=True):\n",
    "        var_pred_list.append(temp_pred_dict[save])\n",
    "        count_pred = count_pred - 1\n",
    "        if count_pred == 0:\n",
    "            break\n",
    "    return var_pred_list        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_(to_check_string,dataset_label,var_pred_list):\n",
    "    #to_check_string = 'Eggs;Coffee;Oatmeal'\n",
    "    to_pred = []\n",
    "    to_check_string = to_check_string.split(';')\n",
    "    for i in var_pred_list:\n",
    "        ss = str(df[dataset_label][i])\n",
    "        ss = ss.split(';')\n",
    "        for j in ss:\n",
    "            if j not in to_check_string:\n",
    "                to_pred.append(j)\n",
    "    return unique(to_pred)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1):  \n",
    "    unique_list = [] \n",
    "    for x in list1: \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x)\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_check_string = 'Poori with Aloo Sabsi'\n",
    "df_label_features = 'Eggs;Coffee;Oatmeal;Green Tea;Chai;Protein Shake;Fruit;Milk;Aloo Paratha;Onion Paratha;Dahlia;Poori with Aloo Sabsi;Pav bhaji;Chole Bhathure'\n",
    "dataset_label = 'Breakfast'\n",
    "kaka = pred_util(to_check_string,df_label_features,dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chai',\n",
       " 'Milk',\n",
       " 'Aloo Paratha',\n",
       " 'Fruit',\n",
       " 'Eggs',\n",
       " 'Coffee',\n",
       " 'Onion Paratha',\n",
       " 'Chole Bhathure']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Momos',\n",
       " 'Cutlet;Falooda;Momos',\n",
       " 'Cutlet;Momos',\n",
       " 'Falooda;Momos',\n",
       " 'Lettuce;Cutlet;Falooda;Momos',\n",
       " 'Cutlet;Falooda;Momos;Smashed Unripe Banana',\n",
       " 'Cutlet',\n",
       " 'Pura;Cutlet;Falooda;Momos',\n",
       " 'Lettuce;Khar;Cutlet;Falooda;Momos',\n",
       " 'Laru',\n",
       " 'Smashed Unripe Banana',\n",
       " 'Cutlet;Momos;Smashed Unripe Banana',\n",
       " 'Lettuce;Poitabhat;Cutlet;Falooda;Momos',\n",
       " 'Lettuce;Falooda;Momos',\n",
       " 'Falooda;Momos;Shukto',\n",
       " 'Cutlet;Falooda',\n",
       " 'Lettuce;Cutlet;Falooda;Momos;Smashed Unripe Banana',\n",
       " 'Momos;Smashed Unripe Banana',\n",
       " 'Khar;Momos',\n",
       " 'Lettuce',\n",
       " 'Falooda',\n",
       " 'Lettuce;Cutlet;Momos;Shukto',\n",
       " 'Lettuce;Apong;Khar;Masor Tenga;Pura;Poitabhat;Pitika;Laru;Poodla;Cutlet;Falooda;Momos;Smashed Unripe Banana;Shukto']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df['NEI_cuisine'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
